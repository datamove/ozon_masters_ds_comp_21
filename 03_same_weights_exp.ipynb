{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, RandomSampler, Dataset\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train_mean_median_max_min_current_next_prev.csv.zip')\n",
    "df_test = pd.read_csv('./data/test_mean_median_max_min_current_next_prev.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X2_next_min</th>\n",
       "      <th>X4_next_min</th>\n",
       "      <th>X2_prev_min</th>\n",
       "      <th>X4_prev_min</th>\n",
       "      <th>X2_current_min</th>\n",
       "      <th>X4_current_min</th>\n",
       "      <th>to_next_game_1</th>\n",
       "      <th>to_next_game_2</th>\n",
       "      <th>to_prev_game_1</th>\n",
       "      <th>to_prev_game_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>908749</td>\n",
       "      <td>954</td>\n",
       "      <td>480270</td>\n",
       "      <td>935</td>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "      <td>53</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>780</td>\n",
       "      <td>905</td>\n",
       "      <td>867</td>\n",
       "      <td>931</td>\n",
       "      <td>954</td>\n",
       "      <td>935</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>438444</td>\n",
       "      <td>2162</td>\n",
       "      <td>486685</td>\n",
       "      <td>2154</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>2110</td>\n",
       "      <td>2096</td>\n",
       "      <td>2224</td>\n",
       "      <td>2126</td>\n",
       "      <td>2026</td>\n",
       "      <td>2034</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>596915</td>\n",
       "      <td>2066</td>\n",
       "      <td>711059</td>\n",
       "      <td>2081</td>\n",
       "      <td>43</td>\n",
       "      <td>21</td>\n",
       "      <td>58</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>1822</td>\n",
       "      <td>2153</td>\n",
       "      <td>2092</td>\n",
       "      <td>2047</td>\n",
       "      <td>1883</td>\n",
       "      <td>2053</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>625198</td>\n",
       "      <td>1508</td>\n",
       "      <td>66810</td>\n",
       "      <td>1474</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>1502</td>\n",
       "      <td>1416</td>\n",
       "      <td>1506</td>\n",
       "      <td>1564</td>\n",
       "      <td>1502</td>\n",
       "      <td>1474</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>228654</td>\n",
       "      <td>1202</td>\n",
       "      <td>542816</td>\n",
       "      <td>1196</td>\n",
       "      <td>53</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1264</td>\n",
       "      <td>1239</td>\n",
       "      <td>1162</td>\n",
       "      <td>1202</td>\n",
       "      <td>1191</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  X0      X1    X2      X3    X4  X5  X6  X7  X8  ...  X2_next_min  \\\n",
       "0   0   2  908749   954  480270   935  71  79  53  89  ...          780   \n",
       "1   1   1  438444  2162  486685  2154  32  39  48  49  ...         2110   \n",
       "2   2   1  596915  2066  711059  2081  43  21  58  94  ...         1822   \n",
       "3   3   1  625198  1508   66810  1474   7   1  34  73  ...         1502   \n",
       "4   4   2  228654  1202  542816  1196  53  35  16  80  ...         1263   \n",
       "\n",
       "   X4_next_min  X2_prev_min  X4_prev_min  X2_current_min  X4_current_min  \\\n",
       "0          905          867          931             954             935   \n",
       "1         2096         2224         2126            2026            2034   \n",
       "2         2153         2092         2047            1883            2053   \n",
       "3         1416         1506         1564            1502            1474   \n",
       "4         1264         1239         1162            1202            1191   \n",
       "\n",
       "   to_next_game_1  to_next_game_2  to_prev_game_1  to_prev_game_2  \n",
       "0              40               1               2               7  \n",
       "1              17              13               8               1  \n",
       "2               1               1               2               4  \n",
       "3               1               1               1              26  \n",
       "4               8              10              19               1  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['set'] = 'test'\n",
    "df_train['set'] = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "df_all = df_train.append(df_test)\n",
    "df_all =df_all[df_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = MultiLabelBinarizer(classes=np.arange(0,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "fig_1 = binarizer.fit_transform(df_all.iloc[:, 6:14].as_matrix())\n",
    "fig_2 = binarizer.transform(df_all.iloc[:, 14:22].as_matrix())\n",
    "columns_1 = [f'fig_1_{ind}' for ind in np.arange(0,101)]\n",
    "columns_2 = [f'fig_2_{ind}' for ind in np.arange(0,101)]\n",
    "fig_1 = pd.DataFrame(fig_1, columns=columns_1)\n",
    "fig_2 = pd.DataFrame(fig_2, columns=columns_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.reset_index()\n",
    "df_all = pd.concat([df_all, fig_1, fig_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.sort_values(by=['X21'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149649     7\n",
       "2870902    7\n",
       "1508534    7\n",
       "2525939    7\n",
       "3786209    7\n",
       "2525745    7\n",
       "2525125    7\n",
       "4357924    7\n",
       "3784646    7\n",
       "3784630    7\n",
       "1507189    7\n",
       "1516805    7\n",
       "1517551    7\n",
       "1518739    7\n",
       "1520450    7\n",
       "3779162    7\n",
       "528817     7\n",
       "4358767    7\n",
       "3778648    7\n",
       "3778584    7\n",
       "Name: X21, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(20)['X21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4541257it [07:27, 10142.18it/s]\n"
     ]
    }
   ],
   "source": [
    "player_to_exp = defaultdict(int)\n",
    "exp_1 = []\n",
    "exp_2 = []\n",
    "for ind, line in tqdm(df_all.iterrows()):\n",
    "\n",
    "      player_1 = line['X1']\n",
    "      player_2 = line['X3']\n",
    "      player_to_exp[player_1] += 1\n",
    "      player_to_exp[player_2] += 1\n",
    "      exp_1.append(player_to_exp[player_1])\n",
    "      exp_2.append(player_to_exp[player_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['exp_1'] = exp_1\n",
    "df_all['exp_2'] = exp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4541257it [19:33, 3871.01it/s]\n"
     ]
    }
   ],
   "source": [
    "player_to_cum = defaultdict(int)\n",
    "cum_1 = []\n",
    "cum_2 = []\n",
    "for ind, line in tqdm(df_all.iterrows()):\n",
    "\n",
    "      current_1 = line.iloc[54:155].values\n",
    "      current_2 = line.iloc[155:256].values\n",
    "\n",
    "      player_to_cum[line['X1']] += current_1\n",
    "      player_to_cum[line['X3']] += current_2\n",
    "      cum_1.append(player_to_cum[line['X1']] * current_1)\n",
    "      cum_2.append(player_to_cum[line['X3']] * current_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149649     7\n",
       "2870902    7\n",
       "1508534    7\n",
       "2525939    7\n",
       "3786209    7\n",
       "2525745    7\n",
       "2525125    7\n",
       "4357924    7\n",
       "3784646    7\n",
       "3784630    7\n",
       "1507189    7\n",
       "1516805    7\n",
       "1517551    7\n",
       "1518739    7\n",
       "1520450    7\n",
       "3779162    7\n",
       "528817     7\n",
       "4358767    7\n",
       "3778648    7\n",
       "3778584    7\n",
       "Name: X21, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(20)['X21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_1_cum = [f'fig_1_{ind}_cum' for ind in np.arange(0,101)]\n",
    "columns_2_cum = [f'fig_2_{ind}_cum' for ind in np.arange(0,101)]\n",
    "fig_1_cum = pd.DataFrame(cum_1, columns=columns_1_cum)\n",
    "fig_2_cum = pd.DataFrame(cum_2, columns=columns_2_cum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.reset_index()\n",
    "df_all = pd.concat([df_all, fig_1_cum, fig_2_cum], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_all[df_all['set']=='test']\n",
    "df_test = df_test.sort_values(by=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_all[df_all['set']=='train']\n",
    "df_train = df_train.sort_values(by=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>...</th>\n",
       "      <th>fig_2_91_cum</th>\n",
       "      <th>fig_2_92_cum</th>\n",
       "      <th>fig_2_93_cum</th>\n",
       "      <th>fig_2_94_cum</th>\n",
       "      <th>fig_2_95_cum</th>\n",
       "      <th>fig_2_96_cum</th>\n",
       "      <th>fig_2_97_cum</th>\n",
       "      <th>fig_2_98_cum</th>\n",
       "      <th>fig_2_99_cum</th>\n",
       "      <th>fig_2_100_cum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>676977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>908749</td>\n",
       "      <td>954</td>\n",
       "      <td>480270</td>\n",
       "      <td>935</td>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2906432</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>438444</td>\n",
       "      <td>2162</td>\n",
       "      <td>486685</td>\n",
       "      <td>2154</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2453996</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>596915</td>\n",
       "      <td>2066</td>\n",
       "      <td>711059</td>\n",
       "      <td>2081</td>\n",
       "      <td>43</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2549512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>625198</td>\n",
       "      <td>1508</td>\n",
       "      <td>66810</td>\n",
       "      <td>1474</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4032063</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>228654</td>\n",
       "      <td>1202</td>\n",
       "      <td>542816</td>\n",
       "      <td>1196</td>\n",
       "      <td>53</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 461 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         level_0  index  id  X0      X1    X2      X3    X4  X5  X6  ...  \\\n",
       "676977         0      0   0   2  908749   954  480270   935  71  79  ...   \n",
       "2906432        1      1   1   1  438444  2162  486685  2154  32  39  ...   \n",
       "2453996        2      2   2   1  596915  2066  711059  2081  43  21  ...   \n",
       "2549512        3      3   3   1  625198  1508   66810  1474   7   1  ...   \n",
       "4032063        4      4   4   2  228654  1202  542816  1196  53  35  ...   \n",
       "\n",
       "         fig_2_91_cum  fig_2_92_cum  fig_2_93_cum  fig_2_94_cum  fig_2_95_cum  \\\n",
       "676977              0             0             0             0             0   \n",
       "2906432            33             0             0            28             0   \n",
       "2453996             0             0             0             0             0   \n",
       "2549512             0             0             0             0             0   \n",
       "4032063             0             0             0             0            49   \n",
       "\n",
       "         fig_2_96_cum  fig_2_97_cum  fig_2_98_cum  fig_2_99_cum  fig_2_100_cum  \n",
       "676977              0             0             0             0             43  \n",
       "2906432             0             0             0             0              0  \n",
       "2453996             0             0             0             0              0  \n",
       "2549512             0             5             0             0              0  \n",
       "4032063             0             0             0             0              0  \n",
       "\n",
       "[5 rows x 461 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "fig_1_train = df_train[columns_1_cum].as_matrix()\n",
    "fig_2_train = df_train[columns_2_cum].as_matrix()\n",
    "fig_1_test = df_test[columns_1_cum].as_matrix()\n",
    "fig_2_test = df_test[columns_2_cum].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "fig_1_train = np.log(fig_1_train) + 1\n",
    "fig_1_train[fig_1_train<0] = 0\n",
    "fig_2_train = np.log(fig_2_train) + 1\n",
    "fig_2_train[fig_2_train<0] = 0\n",
    "\n",
    "fig_1_test = np.log(fig_1_test) + 1\n",
    "fig_1_test[fig_1_test<0] = 0\n",
    "fig_2_test = np.log(fig_2_train) + 1\n",
    "fig_2_test[fig_2_test<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['1/to_next_game_1'] = df_train['to_next_game_1'].apply(lambda x: x if x==0 else 1/x)\n",
    "df_train['1/to_next_game_2'] = df_train['to_next_game_2'].apply(lambda x: x if x==0 else 1/x)\n",
    "df_train['1/to_prev_game_1'] = df_train['to_prev_game_1'].apply(lambda x: x if x==0 else 1/x)\n",
    "df_train['1/to_prev_game_2'] = df_train['to_prev_game_2'].apply(lambda x: x if x==0 else 1/x)\n",
    "\n",
    "df_test['1/to_next_game_1'] = df_test['to_next_game_1'].apply(lambda x: x if x==0 else 1/x)\n",
    "df_test['1/to_next_game_2'] = df_test['to_next_game_2'].apply(lambda x: x if x==0 else 1/x)\n",
    "df_test['1/to_prev_game_1'] = df_test['to_prev_game_1'].apply(lambda x: x if x==0 else 1/x)\n",
    "df_test['1/to_prev_game_2'] = df_test['to_prev_game_2'].apply(lambda x: x if x==0 else 1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_1_train = df_train[['X2',\n",
    "                           'X2_next_mean',  'X2_prev_mean','X2_current_mean',\n",
    "                           'X2_next_median', 'X2_prev_median','X2_current_median',\n",
    "                           'X2_next_max', 'X2_prev_max', 'X2_current_max', \n",
    "                           'X2_next_min', 'X2_prev_min', 'X2_current_min',\n",
    "                           'to_next_game_1', 'to_prev_game_1', \n",
    "                           '1/to_next_game_1','1/to_prev_game_1', 'exp_1']].values\n",
    "rating_2_train = df_train[['X4',\n",
    "                           'X4_next_mean',  'X4_prev_mean','X4_current_mean',\n",
    "                           'X4_next_median', 'X4_prev_median','X4_current_median',\n",
    "                           'X4_next_max', 'X4_prev_max', 'X4_current_max', \n",
    "                           'X4_next_min', 'X4_prev_min', 'X4_current_min',\n",
    "                           'to_next_game_2', 'to_prev_game_2', \n",
    "                           '1/to_next_game_2','1/to_prev_game_2', 'exp_2']].values\n",
    "\n",
    "rating_1_test =  df_test[['X2',\n",
    "                           'X2_next_mean',  'X2_prev_mean','X2_current_mean',\n",
    "                           'X2_next_median', 'X2_prev_median','X2_current_median',\n",
    "                           'X2_next_max', 'X2_prev_max', 'X2_current_max', \n",
    "                           'X2_next_min', 'X2_prev_min', 'X2_current_min',\n",
    "                           'to_next_game_1', 'to_prev_game_1', \n",
    "                           '1/to_next_game_1','1/to_prev_game_1', 'exp_1']].values\n",
    "rating_2_test = df_test[['X4',\n",
    "                           'X4_next_mean',  'X4_prev_mean','X4_current_mean',\n",
    "                           'X4_next_median', 'X4_prev_median','X4_current_median',\n",
    "                           'X4_next_max', 'X4_prev_max', 'X4_current_max', \n",
    "                           'X4_next_min', 'X4_prev_min', 'X4_current_min',\n",
    "                           'to_next_game_2', 'to_prev_game_2', \n",
    "                           '1/to_next_game_2','1/to_prev_game_2', 'exp_2']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['target']\n",
    "rating_1_train, rating_2_train, fig_1_train, fig_2_train, y_train = shuffle(rating_1_train, rating_2_train, fig_1_train, fig_2_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_1_train, rating_1_val, \\\n",
    "rating_2_train, rating_2_val, \\\n",
    "fig_1_train, fig_1_val, \\\n",
    "fig_2_train, fig_2_val, \\\n",
    "y_train, y_val = train_test_split(rating_1_train, rating_2_train, fig_1_train, fig_2_train, y_train, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figs_train = np.concatenate([fig_1_train, fig_2_train], axis=1)\n",
    "# figs_val = np.concatenate([fig_1_val, fig_2_val], axis=1)\n",
    "# figs_test = np.concatenate([fig_1_test, fig_2_test], axis=1)\n",
    "\n",
    "# rating_train = np.concatenate([rating_1_train, rating_2_train], axis=1)\n",
    "# rating_val = np.concatenate([rating_1_val, rating_2_val], axis=1)\n",
    "# rating_test = np.concatenate([rating_1_test, rating_2_test], axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, figs_1, figs_2, rating_1, rating_2, y):\n",
    "        self.figs_1 = torch.tensor(figs_1, dtype=torch.float)\n",
    "        self.figs_2 = torch.tensor(figs_2, dtype=torch.float)\n",
    "        self.rating_1 = torch.tensor(rating_1, dtype=torch.float)\n",
    "        self.rating_2 = torch.tensor(rating_2, dtype=torch.float)\n",
    "        self.y = torch.tensor(y.tolist(), dtype=torch.float)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.figs_1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # можно добавить случайный своп\n",
    "        return {\n",
    "            'figs_1': self.figs_1[idx],\n",
    "            'figs_2': self.figs_2[idx],\n",
    "            'rating_1': self.rating_1[idx],\n",
    "            'rating_2': self.rating_2[idx],\n",
    "            'y': self.y[idx]\n",
    "        }\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,  figs_1, figs_2, rating_1, rating_2):\n",
    "        self.figs_1 = torch.tensor(figs_1, dtype=torch.float)\n",
    "        self.figs_2 = torch.tensor(figs_2, dtype=torch.float)\n",
    "        self.rating_1 = torch.tensor(rating_1, dtype=torch.float)\n",
    "        self.rating_2 = torch.tensor(rating_2, dtype=torch.float)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.figs_1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        {\n",
    "            'figs_1': self.figs_1[idx],\n",
    "            'figs_2': self.figs_2[idx],\n",
    "            'rating_1': self.rating_1[idx],\n",
    "            'rating_2': self.rating_2[idx],\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(iterator, optimizer, criterion):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for i, batch in tqdm(enumerate(iterator)):\n",
    "            targets = batch['y'].to(device)\n",
    "            figs_1 = batch['figs_1'].to(device)\n",
    "            figs_2 = batch['figs_2'].to(device)\n",
    "            rating_1 = batch['rating_1'].to(device)\n",
    "            rating_2 = batch['rating_2'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(figs_1, figs_2, rating_1, rating_2).squeeze()\n",
    "            loss = criterion(logits, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        return epoch_loss / len(iterator)\n",
    "    \n",
    "def val_epoch(iterator,criterion):\n",
    "        model.eval()\n",
    "        epoch_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, batch in tqdm(enumerate(iterator)):\n",
    "                targets = batch['y'].to(device)\n",
    "                figs_1 = batch['figs_1'].to(device)\n",
    "                figs_2 = batch['figs_2'].to(device)\n",
    "                rating_1 = batch['rating_1'].to(device)\n",
    "                rating_2 = batch['rating_2'].to(device)\n",
    "    \n",
    "                logits = model(figs_1, figs_2, rating_1, rating_2).squeeze()\n",
    "                loss = criterion(logits, targets)\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "        return epoch_loss / len(iterator)\n",
    "    \n",
    "def predict(iterator):\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for i, batch in tqdm(enumerate(iterator)):\n",
    "                figs_1 = batch['figs_1'].to(device)\n",
    "                figs_2 = batch['figs_2'].to(device)\n",
    "                rating_1 = batch['rating_1'].to(device)\n",
    "                rating_2 = batch['rating_2'].to(device)\n",
    "                pred = model.predict(figs_1, figs_2, rating_1, rating_2)\n",
    "                preds += pred.to('cpu').numpy().tolist()\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1figs = nn.Linear(101, 128)\n",
    "        self.bn1figs = nn.BatchNorm1d(128)        \n",
    "        self.fc2figs = nn.Linear(128, 32)\n",
    "        self.bn2figs = nn.BatchNorm1d(32)\n",
    "       \n",
    "        self.fc1rating = nn.Linear(18, 32)\n",
    "        self.bn1rating = nn.BatchNorm1d(32)\n",
    "        self.fc2rating = nn.Linear(32, 16)\n",
    "        self.bn2rating = nn.BatchNorm1d(16)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc1res = nn.Linear(32*1 + 16*1, 32)\n",
    "        self.bn1res = nn.BatchNorm1d(32)\n",
    "        self.fc2res = nn.Linear(32, 1)\n",
    "        \n",
    "        self.do = nn.Dropout(0.5)\n",
    "    \n",
    "    def predict(self, figs_1, figs_2, rating_1, rating_2):\n",
    "        result = self.forward(figs_1, figs_2, rating_1, rating_2)\n",
    "        result = F.sigmoid(result)\n",
    "        return result\n",
    "        \n",
    "    def forward(self, figs_1, figs_2, rating_1, rating_2):\n",
    "        figs_1 = self.fc1figs(figs_1)\n",
    "        figs_1 = self.bn1figs(figs_1)\n",
    "        figs_1 = F.relu(figs_1)\n",
    "        #figs_1 = self.do(figs_1)\n",
    "        \n",
    "        figs_1 = self.fc2figs(figs_1)\n",
    "        figs_1 = self.bn2figs(figs_1)\n",
    "        figs_1 = F.relu(figs_1)\n",
    "        #figs_1 = self.do(figs_1)\n",
    "        \n",
    "        figs_2 = self.fc1figs(figs_2)\n",
    "        figs_2 = self.bn1figs(figs_2)\n",
    "        figs_2 = F.relu(figs_2)\n",
    "        #figs_2 = self.do(figs_2)\n",
    "        \n",
    "        figs_2 = self.fc2figs(figs_2)\n",
    "        figs_2 = self.bn2figs(figs_2)\n",
    "        figs_2 = F.relu(figs_2)\n",
    "        #figs_2 = self.do(figs_2)\n",
    "        \n",
    "        figs_diff = figs_1 - figs_2\n",
    "        #figs_cross = torch.cross(figs_1, figs_2)\n",
    "        \n",
    "        \n",
    "        rating_1 = self.fc1rating(rating_1)\n",
    "        rating_1 = self.bn1rating(rating_1)\n",
    "        rating_1 = F.relu(rating_1)\n",
    "        #rating_1 = self.do(rating_1)\n",
    "        \n",
    "        rating_1 = self.fc2rating(rating_1)\n",
    "        rating_1 = self.bn2rating(rating_1)\n",
    "        rating_1 = F.relu(rating_1)\n",
    "        #rating_1 = self.do(rating_1)\n",
    "        \n",
    "        \n",
    "        rating_2 = self.fc1rating(rating_2)\n",
    "        rating_2 = self.bn1rating(rating_2)\n",
    "        rating_2 = F.relu(rating_2)\n",
    "        #rating_2 = self.do(rating_2)\n",
    "        \n",
    "        rating_2 = self.fc2rating(rating_2)\n",
    "        rating_2 = self.bn2rating(rating_2)\n",
    "        rating_2 = F.relu(rating_2)\n",
    "        #rating_2 = self.do(rating_2)\n",
    "        \n",
    "        rating_diff = rating_1 - rating_2\n",
    "        #rating_cross = torch.cross(rating_1, rating_2)\n",
    "        \n",
    "        features = torch.cat((figs_diff, rating_diff), dim=-1)\n",
    "        features = self.fc1res(features)\n",
    "        features = self.bn1res(features)\n",
    "        features = F.relu(features)\n",
    "        #features = self.do(features)\n",
    "        \n",
    "        result = self.fc2res(features)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = TrainDataset(fig_1_train, fig_2_train, rating_1_train, rating_2_train, y_train)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "valid_dataset = TrainDataset(fig_1_val, fig_2_val, rating_1_val, rating_2_val, y_val)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = TestDataset(fig_1_test, fig_2_test, rating_1_test, rating_2_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2906404, 18)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN()\n",
    "if device == 'cuda':\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.7, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:05, 148.64it/s]\n",
      "11354it [00:21, 526.18it/s]\n",
      "1it [00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      " Train Loss 0.5115197  Val loss 0.535146:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:05, 148.69it/s]\n",
      "11354it [00:21, 523.15it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \n",
      " Train Loss 0.4980472  Val loss 0.5024408:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:04, 149.12it/s]\n",
      "11354it [00:21, 527.10it/s]\n",
      "1it [00:00,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \n",
      " Train Loss 0.494234  Val loss 0.498871:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:04, 149.16it/s]\n",
      "11354it [00:21, 530.49it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \n",
      " Train Loss 0.4921411  Val loss 0.4992591:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:03, 149.81it/s]\n",
      "11354it [00:21, 529.48it/s]\n",
      "1it [00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \n",
      " Train Loss 0.4903314  Val loss 0.5108643:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:04, 149.17it/s]\n",
      "11354it [00:21, 525.84it/s]\n",
      "1it [00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \n",
      " Train Loss 0.486457  Val loss 0.5080293:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:05, 148.67it/s]\n",
      "11354it [00:21, 529.67it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \n",
      " Train Loss 0.4853411  Val loss 0.482652:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:03, 149.40it/s]\n",
      "11354it [00:21, 521.71it/s]\n",
      "1it [00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \n",
      " Train Loss 0.4840466  Val loss 0.4847719:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:02, 150.32it/s]\n",
      "11354it [00:21, 528.19it/s]\n",
      "1it [00:00,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \n",
      " Train Loss 0.4832492  Val loss 0.47719:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:02, 150.27it/s]\n",
      "11354it [00:21, 533.38it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \n",
      " Train Loss 0.4825102  Val loss 0.4845812:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:02, 149.94it/s]\n",
      "11354it [00:21, 530.06it/s]\n",
      "1it [00:00,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \n",
      " Train Loss 0.4800107  Val loss 0.4807609:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:01, 150.49it/s]\n",
      "11354it [00:21, 531.01it/s]\n",
      "1it [00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \n",
      " Train Loss 0.4796271  Val loss 0.4834721:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:00, 151.00it/s]\n",
      "11354it [00:21, 532.48it/s]\n",
      "1it [00:00,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \n",
      " Train Loss 0.4791073  Val loss 0.4786146:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:01, 150.75it/s]\n",
      "11354it [00:21, 532.99it/s]\n",
      "1it [00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \n",
      " Train Loss 0.4788972  Val loss 0.4752133:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:01, 150.61it/s]\n",
      "11354it [00:21, 530.37it/s]\n",
      "1it [00:00,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \n",
      " Train Loss 0.4786123  Val loss 0.4764738:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:00, 151.01it/s]\n",
      "11354it [00:21, 530.29it/s]\n",
      "1it [00:00,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \n",
      " Train Loss 0.4771528  Val loss 0.4726423:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [04:59, 151.41it/s]\n",
      "11354it [00:21, 530.78it/s]\n",
      "1it [00:00,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 \n",
      " Train Loss 0.4769244  Val loss 0.4756026:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:01, 150.86it/s]\n",
      "11354it [00:21, 527.69it/s]\n",
      "1it [00:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 \n",
      " Train Loss 0.4765865  Val loss 0.473383:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:01, 150.74it/s]\n",
      "11354it [00:21, 529.97it/s]\n",
      "1it [00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \n",
      " Train Loss 0.4763858  Val loss 0.4740773:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:01, 150.87it/s]\n",
      "11354it [00:21, 528.64it/s]\n",
      "1it [00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 \n",
      " Train Loss 0.4762806  Val loss 0.4725113:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:01, 150.75it/s]\n",
      "11354it [00:21, 532.91it/s]\n",
      "1it [00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 \n",
      " Train Loss 0.4754309  Val loss 0.472622:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:02, 150.15it/s]\n",
      "11354it [00:21, 532.82it/s]\n",
      "1it [00:00,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 \n",
      " Train Loss 0.4750581  Val loss 0.4737353:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:01, 150.43it/s]\n",
      "11354it [00:21, 533.27it/s]\n",
      "1it [00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 \n",
      " Train Loss 0.4748935  Val loss 0.4736062:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:00, 151.28it/s]\n",
      "11354it [00:21, 531.34it/s]\n",
      "1it [00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 \n",
      " Train Loss 0.4748815  Val loss 0.4703172:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:00, 151.09it/s]\n",
      "11354it [00:21, 537.14it/s]\n",
      "1it [00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 \n",
      " Train Loss 0.4746881  Val loss 0.4737906:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [04:58, 151.89it/s]\n",
      "11354it [00:21, 534.56it/s]\n",
      "1it [00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 \n",
      " Train Loss 0.4737784  Val loss 0.4721302:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [04:58, 152.10it/s]\n",
      "11354it [00:21, 533.19it/s]\n",
      "1it [00:00,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 \n",
      " Train Loss 0.4736987  Val loss 0.4703201:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [04:53, 154.58it/s]\n",
      "11354it [00:21, 528.20it/s]\n",
      "1it [00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 \n",
      " Train Loss 0.4734215  Val loss 0.473321:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [04:59, 151.57it/s]\n",
      "11354it [00:21, 531.26it/s]\n",
      "1it [00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 \n",
      " Train Loss 0.4735311  Val loss 0.4709165:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [04:56, 152.94it/s]\n",
      "11354it [00:21, 534.25it/s]\n",
      "1it [00:00,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 \n",
      " Train Loss 0.4732029  Val loss 0.470387:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:00, 151.09it/s]\n",
      "11354it [00:21, 538.27it/s]\n",
      "1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 \n",
      " Train Loss 0.4727779  Val loss 0.4688022:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:16, 143.42it/s]\n",
      "11354it [00:21, 530.81it/s]\n",
      "1it [00:00,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 \n",
      " Train Loss 0.4726602  Val loss 0.4698099:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:19, 142.00it/s]\n",
      "11354it [00:21, 538.77it/s]\n",
      "1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 \n",
      " Train Loss 0.4725285  Val loss 0.4708377:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:14, 144.60it/s]\n",
      "11354it [00:21, 526.67it/s]\n",
      "1it [00:00,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 \n",
      " Train Loss 0.4726906  Val loss 0.4689047:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:12, 145.41it/s]\n",
      "11354it [00:21, 531.83it/s]\n",
      "1it [00:00,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 \n",
      " Train Loss 0.4724072  Val loss 0.4713466:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:13, 145.07it/s]\n",
      "11354it [00:21, 529.94it/s]\n",
      "1it [00:00,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 \n",
      " Train Loss 0.4720375  Val loss 0.4695564:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:09, 146.73it/s]\n",
      "11354it [00:21, 525.63it/s]\n",
      "1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 \n",
      " Train Loss 0.4720335  Val loss 0.4698415:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:10, 146.15it/s]\n",
      "11354it [00:21, 535.44it/s]\n",
      "1it [00:00,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 \n",
      " Train Loss 0.4719281  Val loss 0.4689717:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:10, 146.23it/s]\n",
      "11354it [00:21, 537.76it/s]\n",
      "1it [00:00,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 \n",
      " Train Loss 0.4719305  Val loss 0.4687099:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45413it [05:11, 145.81it/s]\n",
      "11354it [00:21, 533.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 \n",
      " Train Loss 0.4718574  Val loss 0.4694913:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = round(train_epoch(train_dataloader, optimizer, criterion), 7)\n",
    "    valid_loss = round(val_epoch(valid_dataloader, criterion), 7)\n",
    "    if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), './data/models/same_weights_cum_log_and_exp.pt')\n",
    "\n",
    "    print('Epoch: {} \\n Train Loss {}  Val loss {}:'.format(epoch, train_loss, valid_loss))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./data/models/same_weights_cum_log_and_exp.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11354it [00:21, 534.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4687099"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(val_epoch(valid_dataloader, criterion), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
